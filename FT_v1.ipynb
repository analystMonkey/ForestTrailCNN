{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing import image as image_utils\n",
    "from imagenet_utils import decode_predictions\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 98, 98)    1568        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 98, 98)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 49, 49)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 46, 46)    16416       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 46, 46)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 23, 23)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 20, 20)    16416       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 32, 20, 20)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 10, 10)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 7, 7)      16416       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 32, 7, 7)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 32, 3, 3)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 288)           0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 200)           57800       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 200)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             402         activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 109018\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 101, 101\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_classes=2\n",
    "nb_train_samples = 10800\n",
    "nb_validation_samples = 4700\n",
    "nb_epoch = 100\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 4, 4, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L2 Maxxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L3 Convolutional layer\n",
    "model.add(Convolution2D(32, 4, 4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L4 Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L5 Convolution Layer\n",
    "model.add(Convolution2D(32, 4,4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L6 Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L7 Covolution Layer\n",
    "model.add(Convolution2D(32, 4,4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L8 layer Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#L8 Layer FC\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10800 images belonging to 2 classes.\n",
      "Found 4700 images belonging to 2 classes.\n",
      "[0 0 0 ..., 1 1 1]\n",
      "{'lc': 0, 'rc': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "print(train_generator.classes)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10800/10800 [==============================] - 428s - loss: 0.6683 - acc: 0.6007 - val_loss: 0.6015 - val_acc: 0.7621\n",
      "Epoch 2/100\n",
      "10800/10800 [==============================] - 428s - loss: 0.6826 - acc: 0.5696 - val_loss: 0.6898 - val_acc: 0.5487\n",
      "Epoch 3/100\n",
      "10800/10800 [==============================] - 430s - loss: 0.6840 - acc: 0.5639 - val_loss: 0.6935 - val_acc: 0.4849\n",
      "Epoch 4/100\n",
      "10800/10800 [==============================] - 434s - loss: 0.6773 - acc: 0.5814 - val_loss: 0.6558 - val_acc: 0.6449\n",
      "Epoch 5/100\n",
      "10800/10800 [==============================] - 431s - loss: 0.6718 - acc: 0.5970 - val_loss: 0.6460 - val_acc: 0.6598\n",
      "Epoch 6/100\n",
      "10800/10800 [==============================] - 423s - loss: 0.6629 - acc: 0.6201 - val_loss: 0.7161 - val_acc: 0.5560\n",
      "Epoch 7/100\n",
      "10800/10800 [==============================] - 421s - loss: 0.6779 - acc: 0.5920 - val_loss: 0.6206 - val_acc: 0.6981\n",
      "Epoch 8/100\n",
      "10800/10800 [==============================] - 422s - loss: 0.6897 - acc: 0.5612 - val_loss: 0.6241 - val_acc: 0.6821\n",
      "Epoch 9/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6871 - acc: 0.5576 - val_loss: 0.6897 - val_acc: 0.5374\n",
      "Epoch 10/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6907 - acc: 0.5368 - val_loss: 0.6919 - val_acc: 0.5274\n",
      "Epoch 11/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6906 - val_acc: 0.5357\n",
      "Epoch 12/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6908 - val_acc: 0.5340\n",
      "Epoch 13/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6914 - val_acc: 0.5309\n",
      "Epoch 14/100\n",
      "10800/10800 [==============================] - 415s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6909 - val_acc: 0.5336\n",
      "Epoch 15/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5311\n",
      "Epoch 16/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5323\n",
      "Epoch 17/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5326\n",
      "Epoch 18/100\n",
      "10800/10800 [==============================] - 416s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5315\n",
      "Epoch 19/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5321\n",
      "Epoch 20/100\n",
      "10800/10800 [==============================] - 416s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5313\n",
      "Epoch 21/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6907 - val_acc: 0.5351\n",
      "Epoch 22/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6906 - val_acc: 0.5357\n",
      "Epoch 23/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6922 - val_acc: 0.5240\n",
      "Epoch 24/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6910 - val_acc: 0.5334\n",
      "Epoch 25/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5323\n",
      "Epoch 26/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5277\n",
      "Epoch 27/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6909 - val_acc: 0.5345\n",
      "Epoch 28/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6906 - val_acc: 0.5357\n",
      "Epoch 29/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6915 - val_acc: 0.5296\n",
      "Epoch 30/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5296\n",
      "Epoch 31/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6899 - val_acc: 0.5411\n",
      "Epoch 32/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5311\n",
      "Epoch 33/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5306\n",
      "Epoch 34/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5309\n",
      "Epoch 35/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5302\n",
      "Epoch 36/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6914 - val_acc: 0.5298\n",
      "Epoch 37/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6903 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5366\n",
      "Epoch 38/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6910 - val_acc: 0.5336\n",
      "Epoch 39/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6914 - val_acc: 0.5306\n",
      "Epoch 40/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5317\n",
      "Epoch 41/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6915 - val_acc: 0.5300\n",
      "Epoch 42/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6900 - val_acc: 0.5406\n",
      "Epoch 43/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6925 - val_acc: 0.5228\n",
      "Epoch 44/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5279\n",
      "Epoch 45/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6905 - val_acc: 0.5364\n",
      "Epoch 46/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5296\n",
      "Epoch 47/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6902 - val_acc: 0.5383\n",
      "Epoch 48/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6919 - val_acc: 0.5266\n",
      "Epoch 49/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5313\n",
      "Epoch 50/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5302\n",
      "Epoch 51/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6903 - val_acc: 0.5377\n",
      "Epoch 52/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6904 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5323\n",
      "Epoch 53/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5285\n",
      "Epoch 54/100\n",
      "10800/10800 [==============================] - 422s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5323\n",
      "Epoch 55/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6923 - val_acc: 0.5253\n",
      "Epoch 56/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6902 - val_acc: 0.5391\n",
      "Epoch 57/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6903 - acc: 0.5370 - val_loss: 0.6919 - val_acc: 0.5311\n",
      "Epoch 58/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5323\n",
      "Epoch 59/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5313\n",
      "Epoch 60/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6914 - val_acc: 0.5304\n",
      "Epoch 61/100\n",
      "10800/10800 [==============================] - 421s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6900 - val_acc: 0.5400\n",
      "Epoch 62/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5281\n",
      "Epoch 63/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5315\n",
      "Epoch 64/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6909 - val_acc: 0.5336\n",
      "Epoch 65/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6921 - val_acc: 0.5253\n",
      "Epoch 66/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6902 - val_acc: 0.5387\n",
      "Epoch 67/100\n",
      "10800/10800 [==============================] - 416s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5304\n",
      "Epoch 68/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6903 - val_acc: 0.5379\n",
      "Epoch 69/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6922 - val_acc: 0.5226\n",
      "Epoch 70/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6908 - val_acc: 0.5347\n",
      "Epoch 71/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6909 - val_acc: 0.5332\n",
      "Epoch 72/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5277\n",
      "Epoch 73/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6905 - val_acc: 0.5362\n",
      "Epoch 74/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5294\n",
      "Epoch 75/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5319\n",
      "Epoch 76/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5266\n",
      "Epoch 77/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6902 - val_acc: 0.5389\n",
      "Epoch 78/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5285\n",
      "Epoch 79/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6904 - val_acc: 0.5370\n",
      "Epoch 80/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6910 - val_acc: 0.5330\n",
      "Epoch 81/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5334\n",
      "Epoch 82/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6931 - val_acc: 0.5209\n",
      "Epoch 83/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6899 - val_acc: 0.5404\n",
      "Epoch 84/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6913 - val_acc: 0.5311\n",
      "Epoch 85/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6918 - val_acc: 0.5270\n",
      "Epoch 86/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6907 - val_acc: 0.5349\n",
      "Epoch 87/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6911 - val_acc: 0.5321\n",
      "Epoch 88/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6919 - val_acc: 0.5262\n",
      "Epoch 89/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6900 - val_acc: 0.5398\n",
      "Epoch 90/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5311\n",
      "Epoch 91/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6912 - val_acc: 0.5317\n",
      "Epoch 92/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6904 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5272\n",
      "Epoch 93/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6909 - val_acc: 0.5336\n",
      "Epoch 94/100\n",
      "10800/10800 [==============================] - 422s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6905 - val_acc: 0.5366\n",
      "Epoch 95/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6920 - val_acc: 0.5251\n",
      "Epoch 96/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6908 - val_acc: 0.5353\n",
      "Epoch 97/100\n",
      "10800/10800 [==============================] - 418s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6917 - val_acc: 0.5289\n",
      "Epoch 98/100\n",
      "10800/10800 [==============================] - 420s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6908 - val_acc: 0.5343\n",
      "Epoch 99/100\n",
      "10800/10800 [==============================] - 417s - loss: 0.6906 - acc: 0.5370 - val_loss: 0.6916 - val_acc: 0.5289\n",
      "Epoch 100/100\n",
      "10800/10800 [==============================] - 419s - loss: 0.6905 - acc: 0.5370 - val_loss: 0.6906 - val_acc: 0.5355\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "\n",
    "model.save_weights('third_try_augmentation.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_5 (Convolution2D)  (None, 32, 98, 98)    1568        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 32, 98, 98)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 32, 49, 49)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 32, 46, 46)    16416       maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 32, 46, 46)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 32, 23, 23)    0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 32, 20, 20)    16416       maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 32, 20, 20)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 32, 10, 10)    0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 32, 7, 7)      16416       maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 32, 7, 7)      0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 32, 3, 3)      0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 288)           0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 200)           57800       flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 200)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             402         activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 109018\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights_path = '/home/ashu/Desktop/NN/projects/DroneNavigation/ForestTrail/second_try.h5'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 4, 4, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L2 Maxxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L3 Convolutional layer\n",
    "model.add(Convolution2D(32, 4, 4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L4 Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L5 Convolution Layer\n",
    "model.add(Convolution2D(32, 4,4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L6 Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#L7 Covolution Layer\n",
    "model.add(Convolution2D(32, 4,4))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#L8 layer Maxpool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#L8 Layer FC\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#output layer 2 classes\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#print(model.layers[0].get_weights()[0].shape) # Convolution2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('printing before transpose x', (101, 101, 3))\n",
      "('printing after transpose x', (3, 101, 101))\n",
      "1.0\n",
      "0.0666667\n",
      "(3, 101, 101)\n",
      "30603\n",
      "1/1 [==============================] - 0s\n",
      "('Predicted:', array([[ 0.05874954,  0.94125044]], dtype=float32))\n",
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test for a single sample image\n",
    "import pdb\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('64_rc.jpg')\n",
    "im3 = img.resize((101, 101))\n",
    "\n",
    "#x = im3.img_to_array(im3)\n",
    "x = np.asarray( im3, dtype=\"float32\" )\n",
    "\n",
    "print('printing before transpose x',x.shape)\n",
    "x =np.transpose(x)\n",
    "#x = x.reshape((1,) + x.shape)\n",
    "#x_test =x.reshape(x.shape[0], 1, 28, 28).astype('float32') / 255\n",
    "#x=np.reshape(x, (3,101, 101)) # C-like index ordering\n",
    "print('printing after transpose x',x.shape)\n",
    "\n",
    "#print(x.max())\n",
    "#print(x.min())\n",
    "x = x/255.0\n",
    "print(x.max())\n",
    "print(x.min())\n",
    "print(x.shape)\n",
    "print(x.size)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#print(x.shape)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "preds = model.predict(x)\n",
    "\n",
    "pred=model.predict( x, batch_size=1, verbose=1)\n",
    "print('Predicted:', (pred))\n",
    "model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996, 3, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import PIL\n",
    "\n",
    "dir = '/home/ashu/Desktop/NN/projects/DroneNavigation/ForestTrail/DataSet/011/011/videos/rc/26802465.frames'\n",
    "imList = []\n",
    "X , X_left,X_right, y =[], [], [], []\n",
    "for imageName in sorted(os.listdir(dir)):\n",
    "    #print(imageName)\n",
    "    path =os.path.join(dir,imageName)\n",
    "    #print(path)\n",
    "    with open(path, 'rb') as f:   \n",
    "    #print(imageName)\n",
    "        im = Image.open(f)\n",
    "        img = im.resize((101, 101), Image.BILINEAR)\n",
    "        #print(img.size)\n",
    "        img = np.array(img)\n",
    "        #im=imread(img)\n",
    "        img=img.transpose(2,0,1)\n",
    "        size_im =img.shape\n",
    "        #print(size_im)\n",
    "        #print(size_im[0])\n",
    "        #print(size_im[1])\n",
    "        #print(size_im[2])\n",
    "        #im=Image.open(f)\n",
    "        #x = np.array(im.getdata(),dtype=np.uint8)\n",
    "    y.append(img)\n",
    "    \n",
    "        #y=np.concatenate(y)\n",
    "    \n",
    "y = np.concatenate(y).reshape(-1,3, size_im[1], size_im[2]).astype(np.float32)\n",
    "\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2=model.predict_on_batch( y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755.0\n",
      "('Accuracy on rc', 87.9258517034068)\n"
     ]
    }
   ],
   "source": [
    "test ='rc'\n",
    "\n",
    "if test =='rc':\n",
    "    sum=0.0\n",
    "    for x in (pred2):\n",
    "        if x[1]> x[0]:\n",
    "            sum=sum+1\n",
    "    print(sum)        \n",
    "    print('Accuracy on rc',100 *(sum/len(pred2)))\n",
    "else:\n",
    "    sum=0.0\n",
    "    for x in (pred2):\n",
    "        if x[0]> x[1]:\n",
    "            sum=sum+1\n",
    "    print(sum)        \n",
    "    print(\"Accuracy on lc\",100 *(sum/len(pred2)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE=101\n",
    "# NUM_CLASSES=3\n",
    "\n",
    "# def preprocess_img(img):\n",
    "#     # Histogram normalization in v channel\n",
    "#     hsv = color.rgb2hsv(img)\n",
    "#     hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "#     img = color.hsv2rgb(hsv)\n",
    "\n",
    "#     # central square crop\n",
    "#     min_side = min(img.shape[:-1])\n",
    "#     centre = img.shape[0] // 2, img.shape[1] // 2\n",
    "#     img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
    "#               centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
    "#               :]\n",
    "\n",
    "#     # rescale to standard size\n",
    "#     img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "#     # roll color axis to axis 0\n",
    "#     img = np.rollaxis(img, -1)\n",
    "\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_class(img_path):\n",
    "#     return str(img_path.split('/')[-2])\n",
    "\n",
    "# root_dir = '/home/alienware/Desktop/DeepLearning/ForestTrail/data2/train'\n",
    "# imgs = []\n",
    "# labels = []\n",
    "\n",
    "# all_img_paths = glob.glob(os.path.join(root_dir, '*/*.jpg'))\n",
    "# for img_path in all_img_paths:\n",
    "#     img = io.imread(img_path)\n",
    "#     label = get_class(img_path)\n",
    "#     imgs.append(img)\n",
    "#     labels.append(label)\n",
    "# X = np.array(imgs, dtype='float32')\n",
    "# # Make one hot targets\n",
    "# Y = np.eye(NUM_CLASSES)[labels]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
